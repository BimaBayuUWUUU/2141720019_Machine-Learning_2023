{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsxC9d2uLhDJ"
      },
      "source": [
        "# Praktikum 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j27z52vxLhDK"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KDGVacqLhDK"
      },
      "source": [
        "### Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U9REUpa9LhDK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL8klxvELhDL"
      },
      "source": [
        "### Download Dataset Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VtRYZByRLhDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02fcac7-12fa-4fac-e42b-89697b7b961b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XTjwJPSLhDL"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "33E5xOOJLhDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71748572-135d-464e-c083-63fccf9d2aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eQhNIwW9LhDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aff96ae-d650-4e73-8c11-ebe93d6e0bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IxTo-S4BLhDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502ff90f-8be5-4c3a-e581-5b11e532f82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POxbDbl3LhDN"
      },
      "source": [
        "## Olah Teks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdOX92d_LhDN"
      },
      "source": [
        "### Vectorize Teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JpmkxZcnLhDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02606886-a126-4887-8c46-ec0f6c0501dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "example_texts=['abcdefg','xyz']\n",
        "chars=tf.strings.unicode_split(example_texts,input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JPEoWHciLhDO"
      },
      "outputs": [],
      "source": [
        "ids_from_chars=tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab),mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I56OST5QLhDO"
      },
      "outputs": [],
      "source": [
        "ids_from_chars=tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab),mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aWQxvDeKLhDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739f9beb-5ada-4c74-d8e1-dd238b335325"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ids=ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j8Vz39PQLhDQ"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NG2xiPVMLhDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f0ec48-16e3-490c-930b-ef452bbf77eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "chars=chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F8OeYJMuLhDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daecf95a-35bf-4671-c49c-b3e9402098fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ft0BwFWCLhDR"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gr5JAwXLhDR"
      },
      "source": [
        "### Prediksi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6okaumfLhDR"
      },
      "source": [
        "### Membuat Trianing Set dan Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k3G7TBhiLhDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a1b0cb-600e-48ab-e761-e249f6efc1c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "all_ids=ids_from_chars(tf.strings.unicode_split(text,'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w3xhG062LhDR"
      },
      "outputs": [],
      "source": [
        "ids_dataset=tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C3UXHVa1LhDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277dc8a2-5778-495b-803d-e87e5d611745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hn0z8H-yLhDR"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XZaVPC6-LhDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b83137c-c897-4c08-8362-c0952517b4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "x7oyX5S4LhDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd44265-0c23-4593-98e0-67b6e17021e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jikMACypLhDS"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tWWYZ978LhDS"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ASXuhv8GLhDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc2a70f-2a71-4cee-f131-6b2ee4e88fad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2m5iLGnELhDS"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "chHEg5IvLhDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef705d8-ec7e-4204-a45d-69e8f46508db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeiyytP5LhDT"
      },
      "source": [
        "### Membuat Batch Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u2IfQ0CDLhDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c9e5a7-870c-4c6d-b83e-3faf40f3261a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOUwCjf5LhDT"
      },
      "source": [
        "## Buat Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "g6ybpsLoLhDT"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UJwjViXQLhDU"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "D2SRItTQLhDU"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMO9oNLxLhDX"
      },
      "source": [
        "## Uji Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4cIYzZRQLhDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000263d3-7b17-4255-f7b7-110d1657ab62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "55PaSTOKLhDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3756c53-fbfe-4920-a4b0-6486e1ccfbb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gkZtofCuLhDX"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DTFReN4ALhDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc86c5db-531c-4686-8547-84361c7b7303"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33, 27, 57, 41, 17, 43,  7, 31, 39, 24, 37, 10, 44, 54, 43, 34, 42,\n",
              "       55, 30, 52, 19,  4, 46, 27,  2, 31,  0, 31, 41, 44, 14, 30,  5, 62,\n",
              "       54, 48, 63, 62, 43, 12,  8, 46, 63, 41, 22,  8, 17,  0,  2, 39, 24,\n",
              "       18, 51, 39, 28, 51, 58,  4, 34,  4, 27, 37, 62, 53,  5,  5,  8, 11,\n",
              "       44, 53,  3, 50, 50,  1, 14, 33, 25, 23, 41, 47, 35, 62, 48, 13, 40,\n",
              "       40,  8, 49,  2, 60, 55, 64, 51, 47, 58, 20, 23, 64, 28, 60])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9DQrIE2fLhDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd04a02-cccc-4045-b916-c9202e553189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'o, till I see her;\\nAnd therefore let me be thus bold with you\\nTo give you over at this first encount'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'TNrbDd,RZKX3eodUcpQmF$gN R[UNK]RbeAQ&woixwd;-gxbI-D[UNK] ZKElZOls$U$NXwn&&-:en!kk\\nATLJbhVwi?aa-j upylhsGJyOu'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXsGRBsqLhDY"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isBNoKatLhDY"
      },
      "source": [
        "### Tambahan optimizer dan fungsi loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "t7dHIAGFLhDY"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5V6TMdKcLhDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5269a886-c115-4836-cfac-d15291875d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190149, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "wK0HfAU_LhDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0749b8ca-3e4b-4138-c832-c91c57c362d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.032616"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8uARd7glLhDY"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3huXA0WYLhDZ"
      },
      "source": [
        "### Konfigurasi Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4IjQIwWULhDZ"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVrlHjXcLhDZ"
      },
      "source": [
        "### Lakukan Proses Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QQvGrLo5LhDZ"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pbghN-kOLhDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585f064d-3c2c-4e8f-df67-a8c5b733babf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 14s 58ms/step - loss: 2.7480\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 2.0219\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.7404\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.5745\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.4705\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.3998\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 13s 60ms/step - loss: 1.3462\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 1.3008\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 1.2603\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.2222\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.1840\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.1451\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.1045\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.0619\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.0172\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.9693\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.9209\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.8691\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.8183\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.7695\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0GROFEgLhDZ"
      },
      "source": [
        "## Generate Teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "R4N3w6QbLhDZ"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VNaof3D9LhDa"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wWCYceSrLhDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9ce1e8-5bda-4444-9d8a-137e445a0421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "And for I first my name patience.\n",
            "\n",
            "SICINIUS:\n",
            "Present.\n",
            "\n",
            "Post:\n",
            "Ay, but not prize, and with a truit intelligence\n",
            "And come about so wife in with Camillo!\n",
            "\n",
            "GRUMIO:\n",
            "What comes from your cousin? cousin thou canst go: come to her dear\n",
            "Than honour on your windows; vials follod.\n",
            "\n",
            "HENRY PERCY:\n",
            "Where is the counsell is best take thyself love.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Further of Gloucester, you must war him.\n",
            "\n",
            "KING HENRY VI:\n",
            "Fear notes of York and Gloucester,\n",
            "And once again bestremets of the city.\n",
            "\n",
            "Boatswain:\n",
            "Would God since you are made a brace?\n",
            "Yet you must die? to-do him request,\n",
            "When you should bazed your queen and you are,\n",
            "That thou didst child aloud a day, as welcome,\n",
            "As he is as a beggar crance and spear,\n",
            "And in comes with our country's back and given his faults\n",
            "And may be hide to sleep.\n",
            "\n",
            "LEONTES:\n",
            "What is this is this? how met?\n",
            "Better Venon, farewell. But wilt thou be of word,\n",
            "When it was the care for less o'er her kind of best,\n",
            "But tyealth dowbrike from her dowry shall swear appear,\n",
            "Are you the cr \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.0365118980407715\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Qg8Cf_LhDa"
      },
      "source": [
        "## Ekspor Model Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sy84yIJnLhDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4941221e-6ead-44fb-cee1-743e06570ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x79511085e650>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "keLWT_0yLhDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38611128-19e9-43ad-8744-dc11b740a7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Where have you dance?\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Nay, by myselfen'd, for my good friends;\n",
            "And, by the wills d\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS**"
      ],
      "metadata": {
        "id": "kw3WVC8tiDAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prosedurnya adalah:**\n"
      ],
      "metadata": {
        "id": "3kwy7glMiGMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Jalankan Model dan hitung loss dengan tf.GradientTape."
      ],
      "metadata": {
        "id": "OU1D2YkMiS05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Hitung update dan terapkan pada model dengan optimizer"
      ],
      "metadata": {
        "id": "mW4ult90iXVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "          grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "6KZqb6-px_-2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Kode diatas menerapkan train_step method sesuai dengan  Keras' train_step conventions. Ini opsional, tetapi memungkinkan Anda mengubah perilaku langkah pelatihan dan tetap menggunakan keras Model.compile and Model.fit methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "n659BRXAiiJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "hMEUx81gyJgO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "d05e4dizyOkI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "id": "5BVIB-oQyQ0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3778689f-bdf3-477a-e41d-363ba4db994c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 15s 62ms/step - loss: 2.7132\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7950fcb374c0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Atau jika ingin lebih mengetahui dalamnya, kita bisa membuat custom training loop sendiri:\n",
        "\n"
      ],
      "metadata": {
        "id": "KFrwYgS9isQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "# saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "id": "4KEr9QSriyti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32017701-043f-4918-b4b1-5c272d2a65ee"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1331\n",
            "Epoch 1 Batch 50 Loss 2.0389\n",
            "Epoch 1 Batch 100 Loss 1.9578\n",
            "Epoch 1 Batch 150 Loss 1.8853\n",
            "\n",
            "Epoch 1 Loss: 1.9853\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7785\n",
            "Epoch 2 Batch 50 Loss 1.7594\n",
            "Epoch 2 Batch 100 Loss 1.7122\n",
            "Epoch 2 Batch 150 Loss 1.6216\n",
            "\n",
            "Epoch 2 Loss: 1.7122\n",
            "Time taken for 1 epoch 11.96 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5790\n",
            "Epoch 3 Batch 50 Loss 1.6096\n",
            "Epoch 3 Batch 100 Loss 1.5543\n",
            "Epoch 3 Batch 150 Loss 1.5418\n",
            "\n",
            "Epoch 3 Loss: 1.5536\n",
            "Time taken for 1 epoch 11.72 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4639\n",
            "Epoch 4 Batch 50 Loss 1.4340\n",
            "Epoch 4 Batch 100 Loss 1.4538\n",
            "Epoch 4 Batch 150 Loss 1.4762\n",
            "\n",
            "Epoch 4 Loss: 1.4560\n",
            "Time taken for 1 epoch 11.50 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3895\n",
            "Epoch 5 Batch 50 Loss 1.3706\n",
            "Epoch 5 Batch 100 Loss 1.3497\n",
            "Epoch 5 Batch 150 Loss 1.3856\n",
            "\n",
            "Epoch 5 Loss: 1.3882\n",
            "Time taken for 1 epoch 11.56 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.2929\n",
            "Epoch 6 Batch 50 Loss 1.3254\n",
            "Epoch 6 Batch 100 Loss 1.3074\n",
            "Epoch 6 Batch 150 Loss 1.3136\n",
            "\n",
            "Epoch 6 Loss: 1.3354\n",
            "Time taken for 1 epoch 11.44 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2458\n",
            "Epoch 7 Batch 50 Loss 1.2704\n",
            "Epoch 7 Batch 100 Loss 1.2950\n",
            "Epoch 7 Batch 150 Loss 1.2901\n",
            "\n",
            "Epoch 7 Loss: 1.2910\n",
            "Time taken for 1 epoch 11.50 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2178\n",
            "Epoch 8 Batch 50 Loss 1.2346\n",
            "Epoch 8 Batch 100 Loss 1.2847\n",
            "Epoch 8 Batch 150 Loss 1.2558\n",
            "\n",
            "Epoch 8 Loss: 1.2502\n",
            "Time taken for 1 epoch 11.56 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1910\n",
            "Epoch 9 Batch 50 Loss 1.1833\n",
            "Epoch 9 Batch 100 Loss 1.2289\n",
            "Epoch 9 Batch 150 Loss 1.2525\n",
            "\n",
            "Epoch 9 Loss: 1.2118\n",
            "Time taken for 1 epoch 11.61 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1611\n",
            "Epoch 10 Batch 50 Loss 1.1732\n",
            "Epoch 10 Batch 100 Loss 1.1393\n",
            "Epoch 10 Batch 150 Loss 1.2233\n",
            "\n",
            "Epoch 10 Loss: 1.1726\n",
            "Time taken for 1 epoch 11.66 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?"
      ],
      "metadata": {
        "id": "AUoyKGceidjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terdapat beberapa perbedaan utama antara praktikum 2 dan pelatihan tugas yang jalankan:\n",
        "\n",
        "**1. Model Architectures:**\n",
        "\n",
        "* Praktikum 2 menggunakan model bahasa berdasarkan RNN (Recurrent Neural Network), sementara pelatihan tugas mungkin menggunakan arsitektur yang berbeda, seperti GRU (Gated Recurrent Unit) dalam model .\n",
        "*Praktikum 2 mungkin lebih sederhana dalam hal arsitektur model karena digunakan sebagai demonstrasi dasar. Model pelatihan tugas tampaknya memiliki lapisan embedding, lapisan GRU, dan lapisan dense.\n",
        "\n",
        "**2. Epochs:**\n",
        "\n",
        "* Dalam praktikum 2, menjalankan model selama 20 epoch, sedangkan dalam pelatihan tugas , melatih model selama 10 epoch.\n",
        "\n",
        "**3. Prosedur Pelatihan:**\n",
        "\n",
        "* Praktikum 2 mungkin lebih sederhana dalam hal pelatihan dan menggunakan API model.fit() bawaan Keras.\n",
        "* Dalam pelatihan tugas , mengimplementasikan loop pelatihan khusus dengan menggunakan train_step, yang memberikan lebih banyak kontrol atas proses pelatihan, seperti pengukuran loss, perhitungan gradien, dan optimasi.\n",
        "\n",
        "**4. Output Hasil Pelatihan:**\n",
        "\n",
        "* Hasil dari praktikum 2 adalah informasi singkat tentang loss selama pelatihan tanpa informasi lebih lanjut tentang perbedaan antar epoch atau waktu eksekusi.\n",
        "* Dalam pelatihan tugas , mencantumkan loss untuk setiap batch dan untuk setiap epoch, serta waktu yang diperlukan untuk menjalankan setiap epoch.\n",
        "\n",
        "**5. Waktu Eksekusi:**\n",
        "\n",
        "* Waktu eksekusi per epoch mungkin berbeda di antara kedua eksperimen karena praktikum 2 mungkin lebih cepat dalam pengaturan default, sedangkan dalam pelatihan tugas, waktu eksekusi mungkin lebih lama karena menjalankan model selama lebih banyak epoch.\n",
        "Produk"
      ],
      "metadata": {
        "id": "6UKsD6Coj5xS"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}